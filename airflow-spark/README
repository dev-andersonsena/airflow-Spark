
## Instalando o Python3.9 para funcionamento do airflow


1. sudo apt install python3.9

2. sudo apt install python3.9-venv

3. python3.9 -m venv venv

4. source venv/bin/activate

5. pip install requests==2.27.1

instalando o airflow 

--AIRFLOW_VERSION=2.3.2

--PYTHON_VERSION=3.9

--CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"

--pip install "apache-airflow[postgres,celery,redis]==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"

--export AIRFLOW_HOME=$(pwd)/airflow_pipeline

--airflow standalone

**** baixando o pacote do spark *** 
wget https://archive.apache.org/dist/spark/spark-3.1.3/spark-3.1.3-bin-hadoop3.2.tgz
descompactar = tar -xvzf spark-3.1.3-bin-hadoop3.2.tgz

acessar a pasta bin = ./bin/spark-submit /home/aluno/Documents/curso2/src/spark/transformation.py

pip install

* pip install apache-airflow-providers-apache-spark
